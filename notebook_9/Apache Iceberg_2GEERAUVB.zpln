{
  "paragraphs": [
    {
      "text": "%spark.conf\n\nspark.sql.extensions org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\nspark.sql.catalog.spark_catalog org.apache.iceberg.spark.SparkSessionCatalog\nspark.sql.catalog.spark_catalog.type hive\nspark.sql.catalog.local org.apache.iceberg.spark.SparkCatalog\nspark.sql.catalog.local.type hadoop\nspark.sql.catalog.local.warehouse ./warehouse",
      "user": "anonymous",
      "dateUpdated": "2021-09-02 16:00:26.814",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/text",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1630608577101_162359596",
      "id": "paragraph_1630608577101_162359596",
      "dateCreated": "2021-09-02 15:49:37.101",
      "dateStarted": "2021-09-02 16:00:26.845",
      "dateFinished": "2021-09-02 16:00:26.868",
      "status": "FINISHED"
    },
    {
      "text": "%spark.sql\n\nCREATE TABLE local.db.table1 (id bigint, data string) USING iceberg\n",
      "user": "anonymous",
      "dateUpdated": "2021-09-02 16:00:38.538",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1630607010467_1078575651",
      "id": "paragraph_1630607010467_1078575651",
      "dateCreated": "2021-09-02 15:23:30.467",
      "dateStarted": "2021-09-02 16:00:38.556",
      "dateFinished": "2021-09-02 16:01:06.082",
      "status": "FINISHED"
    },
    {
      "text": "%spark.sql\nCREATE TABLE local.db.table (id bigint, data string) USING iceberg\n",
      "user": "anonymous",
      "dateUpdated": "2021-09-02 16:01:10.683",
      "progress": 0,
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/sql"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1630607027723_316298287",
      "id": "paragraph_1630607027723_316298287",
      "dateCreated": "2021-09-02 15:23:47.723",
      "dateStarted": "2021-09-02 16:01:10.699",
      "dateFinished": "2021-09-02 16:01:10.822",
      "status": "FINISHED"
    },
    {
      "text": "%spark.sql\nINSERT INTO local.db.table VALUES (1, \u0027a\u0027), (2, \u0027b\u0027), (3, \u0027c\u0027);",
      "user": "anonymous",
      "dateUpdated": "2021-09-02 16:01:16.191",
      "progress": 100,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin.bdb:4040/jobs/job?id\u003d0"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1630608968454_1860927426",
      "id": "paragraph_1630608968454_1860927426",
      "dateCreated": "2021-09-02 15:56:08.454",
      "dateStarted": "2021-09-02 16:01:16.208",
      "dateFinished": "2021-09-02 16:01:22.343",
      "status": "FINISHED"
    },
    {
      "text": "%spark.sql\nselect * from  local.db.table",
      "user": "anonymous",
      "dateUpdated": "2021-09-02 16:01:25.256",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "id": "string",
                      "data": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nError happens in sql: \nselect * from  local.db.table\norg.apache.iceberg.exceptions.RuntimeIOException: Failed to get status for file: warehouse/db/table/data/00001-1-4de71ef6-7387-42b6-ad9c-4e7f8f821253-00001.parquet\n\tat org.apache.iceberg.hadoop.HadoopInputFile.lazyStat(HadoopInputFile.java:158)\n\tat org.apache.iceberg.hadoop.HadoopInputFile.getStat(HadoopInputFile.java:192)\n\tat org.apache.iceberg.parquet.ParquetIO.file(ParquetIO.java:54)\n\tat org.apache.iceberg.parquet.ReadConf.newReader(ReadConf.java:218)\n\tat org.apache.iceberg.parquet.ReadConf.\u003cinit\u003e(ReadConf.java:74)\n\tat org.apache.iceberg.parquet.ParquetReader.init(ParquetReader.java:66)\n\tat org.apache.iceberg.parquet.ParquetReader.iterator(ParquetReader.java:77)\n\tat org.apache.iceberg.parquet.ParquetReader.iterator(ParquetReader.java:38)\n\tat org.apache.iceberg.util.Filter.lambda$filter$0(Filter.java:35)\n\tat org.apache.iceberg.io.CloseableIterable$2.iterator(CloseableIterable.java:73)\n\tat org.apache.iceberg.spark.source.RowDataReader.open(RowDataReader.java:78)\n\tat org.apache.iceberg.spark.source.BaseDataReader.next(BaseDataReader.java:93)\n\tat org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:79)\n\tat org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:112)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.io.FileNotFoundException: File warehouse/db/table/data/00001-1-4de71ef6-7387-42b6-ad9c-4e7f8f821253-00001.parquet does not exist\n\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)\n\tat org.apache.iceberg.hadoop.HadoopInputFile.lazyStat(HadoopInputFile.java:156)\n\t... 32 more\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin.bdb:4040/jobs/job?id\u003d1"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1630608977027_809298078",
      "id": "paragraph_1630608977027_809298078",
      "dateCreated": "2021-09-02 15:56:17.027",
      "dateStarted": "2021-09-02 16:01:25.272",
      "dateFinished": "2021-09-02 16:01:28.294",
      "status": "ERROR"
    },
    {
      "text": "%spark.sql\n",
      "user": "anonymous",
      "dateUpdated": "2021-09-02 15:56:32.141",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1630608992140_963815683",
      "id": "paragraph_1630608992140_963815683",
      "dateCreated": "2021-09-02 15:56:32.141",
      "status": "READY"
    }
  ],
  "name": "Apache Iceberg",
  "id": "2GEERAUVB",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}